{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# When the notebook is executed by the widget, this cell is ignored.\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import base64\n",
    "import io\n",
    "\n",
    "additional_parameters = \"{\\\"question\\\":\\\"What is the main organ in the body that is affected by each of the following diseases? [dashboard sample healthcare widget TOP 10 DIAGNOSIS column diagnosis]\\n\\\"\"+ \\\n",
    "\",\\\"widgetId\\\":\\\"63ac28e77a19050033efd92d\\\",\\\"model_name\\\":\\\"Sample Healthcare\\\"\" + \\\n",
    "\",\\\"table_name\\\":\\\"Temp\\\",\\\"cookie\\\":\\\"XXX\\\"}\"\n",
    "\n",
    "\n",
    "df_input = pd.DataFrame()\n",
    "csv_input =  \"QmVmb3JlXG5DT08=\"\n",
    "print('size of csv_input is:' + str(sys.getsizeof(csv_input)) + ' bytes')\n",
    "bytes = base64.b64decode(csv_input).decode('unicode_escape')\n",
    "df_input = pd.read_csv(io.StringIO(bytes), na_values='!#NULL#!')\n",
    "\n",
    "# for local develop\n",
    "# Insert IP of Sisense instance\n",
    "# os.environ['API_GATEWAY_EXTERNAL_SERVICE_HOST'] = \"X.X.X.X\"\n",
    "# # Insert Port of Sisense instance\n",
    "# os.environ['API_GATEWAY_EXTERNAL_SERVICE_PORT'] = \"30845\"\n",
    "# # Insert Cookie received by Sisense REST API - '/authentication/tokens/api'\n",
    "# os.environ['Cookie'] = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "Welcome to the AI-model (GPT) Data Search Notebook.  \n",
    "\n",
    "This notebook shows how to augment data with GPT model. Using this notebook it is possible to:\n",
    "1. Augment sisense data with GPT model, without using existing data in Sisense.\n",
    "1. Augment sisense data with GPT model, with using existing data in Sisense.\n",
    "\n",
    "Data extraction from Sisense can be done in 2 ways:\n",
    "1. Specify the table and column name in the prompt question ([country.country])\n",
    "1. Specify the table and column name in the prompt question ([table country column country])\n",
    "1. Spacify the dashboard, widget and column name in the prompt question ([dashboard sample healthcare widget TOP 10 DIAGNOSIS column diagnosis])\n",
    "\n",
    "The extraction info from sisense column should be described within square bracket (\"Give me the language in the following countries [country.country]\")\n",
    "    \n",
    "---\n",
    "\n",
    "#### Jupyter Notebooks\n",
    "If you are not familiar with Jupyter Notebooks, we suggest reading about it [here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/What%20is%20the%20Jupyter%20Notebook.html).\n",
    "\n",
    "Get to know the Basics of Jupyter Notebooks, including how to add a New Notebook manually to the Jupyter Server [here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Notebook%20Basics.html).\n",
    "\n",
    "---\n",
    "\n",
    "This Tutorial shows the following basic principles:\n",
    "1. Examples for API parameters\n",
    "1. How to parse the prompt question and extract sisense data info.\n",
    "1. How to create requests to GPT model in a batch mode\n",
    "1. How to parse GPT response\n",
    "1. How to insert the response in to a table in a live model\n",
    "1. how to return the response in html format\n",
    "\n",
    "---\n",
    "## Notebook Flow\n",
    "\n",
    "![./BloxAIFlows-DataSearch.png](./BloxAIFlows-DataSearch.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Content\n",
    "  \n",
    "1. [Test Cell](#Test-Cell)\n",
    "2. [Imports](#Imports)\n",
    "3. [Additional Parameters](#Additional-Parameters)\n",
    "4. [Initialize Global Variables](#Initialize-Global-Variables)\n",
    "5. [Search Fields In Sisense](#Search-Fields-In-Sisense)\n",
    "6. [Ask AI Model Questions](#Ask-AI-Model-Questions)\n",
    "7. [Identify The Data Types Of The Generated Data](#Identify-The-Data-Types-Of-The-Generated-Data)\n",
    "8. [Create Table With Generated Data](#Create-Table-With-Generated-Data)\n",
    "9. [Publish The Model](#Publish-The-Model)\n",
    "10. [Return HTML Result](#Return-HTML-Result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='How_to_run_the_notebook'></a>\n",
    "## How to run the notebook\n",
    "There are two options to execute this notebook, the first, which is the default one is via Jupyter server in Sisense instance. We refer this option as the \"Remote\" option.\n",
    "\n",
    "The second one is \"local\" execution via local IDE.\n",
    "\n",
    "The default behavior for the code in this notebook is to run in remote.\n",
    "To run it locally, some code changes are required. To apply the changes, you can uncomment the code under the title - \"for local develop\".\n",
    "\n",
    "The changes are in the following cells:\n",
    "1. [Test Cell](#Test-Cell)\n",
    "    Insert the IP of Sisense instance to environment variable - \"API_GATEWAY_EXTERNAL_SERVICE_HOST\"\n",
    "    Insert the Port of Sisense instance to environment variable - \"API_GATEWAY_EXTERNAL_SERVICE_PORT\"\n",
    "    Insert authentication token for Sisense user to environment variable - \"Cookie\" (How to get Sisense Authentication token is detailed explained [here](https://gitlab.sisense.com/SisenseTeam/DataSciense/bloxai/-/blob/master/README.md))\n",
    "2. [Imports](#Imports)\n",
    "    Change the import statements to local repository structure\n",
    "3. [Additional Parameters](#Additional-Parameters)\n",
    "    Change to extract authentication token from environment variable - \"Cookie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Cell\n",
    "\n",
    "The First notebook cell is a Test Cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Test Cell ?\n",
    "The additional parameters in the Test Cell are sample values. Its purpose is to mimic the additional parameters passed to the notebook from the Sisense Data Model build process. By having this test cell, the notebook can be run independently of the build process for debugging or editing purposes.   \n",
    "When the notebook is executed from the Sisense build process, the test cell is skipped and the additional parameters are passed to the notebook downstream as a JSON string.  \n",
    "You can change the Test cell location by changing its value in the notebook manifest. The default value is always the first notebook cell (cell 0).   \n",
    "\n",
    "> \"cellsDisable\": [0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# for remote develop\n",
    "from AIIntegration import AIIntegration\n",
    "from AIUtils import AIUtils\n",
    "from InferenceQuestionType import QType\n",
    "\n",
    "# for local develop\n",
    "# from custom_code_notebooks.utils.AIIntegration import AIIntegration\n",
    "# from custom_code_notebooks.utils.AIUtils import AIUtils\n",
    "# from custom_code_notebooks.utils.InferenceQuestionType import QType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Parameters\n",
    "\n",
    "Load the additional parameters passed from the query process or those initialized in the Test Cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example multiple parameters are passed to the notebook:\n",
    "1. question: a prompt question from the user (\"Please give me the company industry of the following companies: [Churn75K.NAME])\n",
    "1. widgetId: the widget id of the widget requesting the custom code notebook excecution\n",
    "1. model_name: the model name of the dashboard (and widget) requesting the custom code notebook excecution \n",
    "1. table_name: the table name that will be genereated with the external data\n",
    "1. cookie: sisense user authentication token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (additional_parameters)\n",
    "add_param = json.loads(additional_parameters,strict=False)\n",
    "\n",
    "orig_question = add_param['question'] \n",
    "model_name = add_param['model_name']\n",
    "table_name = add_param['table_name']\n",
    "inputWidgetId = add_param['widgetId']\n",
    "# for remote develop\n",
    "cookie = add_param['cookie']\n",
    "# for local develop\n",
    "# cookie = os.getenv(\"Cookie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Global Variables\n",
    "\n",
    "the next cell will initialize the following variables:\n",
    "\n",
    "**abort** - boolean value, indicate if the process got an exception or unexpected behavior and should stop execution.\n",
    "\n",
    "**df_result** - dataFrame that will contain the notebook's output, the default value will indicate that 'Something went wrong'.\n",
    "\n",
    "**model** - data model object- corresponding to model_name parameter.\n",
    "\n",
    "**oai** - a connection to ai integration library\n",
    "\n",
    "**utils** - a connection to utils library, contain a logger array that used as time tracking for performance logging. also contain a logger array that used as query tracker for both AI model and Jaql queries.\n",
    "\n",
    "\n",
    "**num_item_per_split** - number of items in a batch mode, to query with sisense data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abort = False\n",
    "utils = AIUtils(inputWidgetId, model_name, add_param, cookie)\n",
    "utils.add_time('Start')\n",
    "\n",
    "df_result = pd.DataFrame(data=['Something went wrong'], columns=['Error'])\n",
    "\n",
    "model = utils.get_model(model_name)\n",
    "datamodelId = model['oid']\n",
    "\n",
    "datasetId = model['datasets'][0]['oid']\n",
    "\n",
    "\n",
    "utils.add_time('before import')\n",
    "oai = AIIntegration(utils)\n",
    "utils.add_time('After import')\n",
    "\n",
    "num_item_per_split = 8\n",
    "\n",
    "utils.write_text_to_log_updates('<H1>AI start searching</H1>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Fields In Sisense\n",
    "Query data from Sisense if asked in the prompt question [BigOpportunity.ACCOUNT_NAME__C]\n",
    "## Steps:\n",
    "1. Identify question type from prompt\n",
    "2. Identify entities in the prompt\n",
    "3. Get relevant dashboard/widget candidates from Sisense\n",
    "4. Identify the candidates that best fit to prompt entities\n",
    "5. Query data from Sisense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = orig_question + \"\\noutput format as JSON.\\n\"\n",
    "prompt = question + '\\n'\n",
    "prompt_vec = [prompt]\n",
    "# extract text from square brackets\n",
    "get_columns_from_model = re.findall(r'\\[.*?\\]',question)\n",
    "\n",
    "\n",
    "if len(get_columns_from_model) > 0:\n",
    "    requested_data = get_columns_from_model[0]\n",
    "    print(\"requested_column \" + requested_data)\n",
    "    options = [QType.TypeColumnTable,QType.TypeDashboardWidgetColumn]\n",
    "    [jaql, info, question_type_object] = oai.get_elements(model_name,requested_data,options)\n",
    "    \n",
    "    utils.write_log_updates()\n",
    "\n",
    "    if info[0].startswith('Error'):\n",
    "        df_result = oai.handle_error_in_element_extraction(info[0])\n",
    "    abort, data = oai.get_data_from_jaql(jaql, model_name) \n",
    "    if not abort:\n",
    "        column_data = oai.get_column_data(data, jaql, question_type_object) \n",
    "        prompt_vec = oai.generate_query_to_ai_based_on_column_data(orig_question, requested_data, column_data, num_item_per_split) \n",
    "        \n",
    "    utils.write_log_updates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask AI Model Questions\n",
    "Since Sisense data can be large, we split the questions to AI model and ask it in batch mode, where each quaesion contain subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not abort:\n",
    "    ai_responses = oai.ask_ai_in_batch_mode(prompt_vec)\n",
    "    abort, df_result = oai.combine_responses_in_batch_mode(prompt_vec, ai_responses, num_item_per_split)\n",
    "    \n",
    "utils.write_log_updates()   \n",
    "df_result.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify The Data Types Of The Generated Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not abort:\n",
    "    types = oai.get_data_types_for_response(df_result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Table With Generated Data\n",
    "## steps:\n",
    "1. Building the import query\n",
    "2. Delete table with same name as output table (if exist)\n",
    "3. Create output table with sql import query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not abort:\n",
    "    sql_import_query = utils.get_import_query(df_result, model, types)\n",
    "    utils.delete_table(model, table_name)\n",
    "    df_result_keys = df_result.keys()\n",
    "    utils.create_table_with_query(model, sql_import_query, table_name, types, df_result_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish The Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not abort:\n",
    "    utils.publish_model(model_name, datamodelId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return HTML Result\n",
    "## steps:\n",
    "1. Create a jaql widget based on output table\n",
    "2. create HTML result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_pararm_str = \"\"\n",
    "if not abort:\n",
    "    widget_pararm_str = utils.get_output_widget_jaql(table_name, types, df_result_keys)\n",
    "df_result = utils.generate_html_result(widget_pararm_str, df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, HTML\n",
    "# display(HTML(\"<html>\" + df_result['output'][0]+\"</html>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
